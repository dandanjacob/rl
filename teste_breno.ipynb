{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importação das bibliotecas necessárias\n",
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import rl\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Convolution2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from rl.agents import DQNAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificação de ambientação\n",
    "# Verifica se o ambiente está registrado\n",
    "keys = gym.envs.registry.keys()\n",
    "print(\"ALE/Assault-v5\" in keys)\n",
    "\n",
    "# Cria o ambiente\n",
    "env = gym.make(\"ALE/Assault-v5\", render_mode=\"rgb_array\", obs_type=\"rgb\", full_action_space=False)\n",
    "\n",
    "# Verifica o espaço de observação e ações\n",
    "height, width, channels = env.observation_space.shape\n",
    "actions = env.action_space.n\n",
    "print(f\"Height: {height}, Width: {width}, Channels: {channels}\")\n",
    "print(f\"Actions: {actions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aleatório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste de execução\n",
    "from copy import deepcopy\n",
    "EPISODES = 1\n",
    "for episode in range(1, EPISODES + 1):\n",
    "    state = env.reset()\n",
    "    DONE = False\n",
    "    SCORE = 0\n",
    "\n",
    "    # Loop de execução\n",
    "    while not DONE:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, DONE, TRUNCATED, info = env.step(action)\n",
    "        SCORE += reward\n",
    "\n",
    "    # Exibe o resultado do episódio\n",
    "    print(f\"Episode: {episode}/{EPISODES}, Score: {SCORE}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(height, width, channels, actions):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, (8,8), strides=(4,4), activation='relu', input_shape=(height, width, channels)))\n",
    "    model.add(Convolution2D(64, (4,4), strides=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(64, (3,3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    #model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(height, width, channels, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SequentialMemory(limit=1000000, window_length=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1.0, value_min=0.1, value_test=0.05, nb_steps=1000000)\n",
    "    memory = SequentialMemory(limit=1000000, window_length=4)\n",
    "    dqn = DQNAgent(model=model, policy=policy, nb_actions=actions, memory=memory, nb_steps_warmup=50000, target_model_update=10000)\n",
    "\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam(learning_rate=1e-4), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.fit(env, nb_steps=10000, visualize=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dqn.test(env, nb_episodes=5, visualize=True)\n",
    "print(np.mean(scores.history['episode_reward']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assault",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
